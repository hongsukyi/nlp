{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HprTbMQqN9Hs"
      },
      "outputs": [],
      "source": [
        "# ì†Œë°©ì²­ ë¯¼ì›ì²˜ë¦¬ AI Agent êµìœ¡ (ê°•ì‚¬ ë²„ì „)\n",
        "# ì‹¤ìŠµ ê³¼ì • - Colab ì „ìš©\n",
        "\n",
        "\"\"\"\n",
        "êµìœ¡ ëª©í‘œ: ì†Œë°© ë¯¼ì› ìë™ ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•\n",
        "- RAG ê¸°ë°˜ ë²•ë ¹/ê°€ì´ë“œ ê²€ìƒ‰\n",
        "- AI ë³´ê³ ì„œ ìë™ ìƒì„±\n",
        "- Gradio UI êµ¬í˜„\n",
        "\n",
        "Lab êµ¬ì„±:\n",
        "1. ë¯¼ì› ìë™ ë¶„ë¥˜ (API ì‹¤ìŠµ í¬í•¨)\n",
        "2. RAG ê¸°ì´ˆ - ì†Œë°©ê¸°ë³¸ë²• (10p)\n",
        "3. ê³ ê¸‰ ê²€ìƒ‰ - í™”ì¬ì˜ˆë°© (44p)\n",
        "4. ë³´ê³ ì„œ ìë™ ìƒì„±\n",
        "5. Gradio UI + ìµœì¢… í†µí•©\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ”§ í™˜ê²½ ì„¤ì •\n",
        "# ============================================================\n",
        "\n",
        "import sys,os\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip install openai chromadb pypdf2 gradio python-dotenv pdfplumber -q\n",
        "    #!pip install openai==1.12.0 chromadb==0.4.22 pypdf2==3.0.1 gradio==4.19.0 python-dotenv==1.0.0 -q\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import pdfplumber\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "import gradio as gr\n",
        "from typing import List, Dict\n",
        "import time\n",
        "\n",
        "# API í‚¤ ì„¤ì •\n",
        "print(\" OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”\")\n",
        "my_api_key = \"\".strip()\n",
        "\n",
        "#api_key = getpass.getpass(my_api_key)\n",
        "client = OpenAI(api_key=my_api_key)\n",
        "\n",
        "print(\" í™˜ê²½ ì„¤ì • ì™„ë£Œ!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbMbvpSQRzW8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================\n",
        "# Lab 1: ë¯¼ì› ìë™ ë¶„ë¥˜ + API ì‹¤ìŠµ (40ë¶„)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"[Lab 1] ë¯¼ì› ìë™ ë¶„ë¥˜ + OpenAI API ì‹¤ìŠµ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ì‹¤ìŠµìš© ë¯¼ì› ìƒ˜í”Œ\n",
        "sample_complaints = [\n",
        "    \"ì•„íŒŒíŠ¸ ë³µë„ì— ì†Œí™”ê¸°ê°€ ì—†ëŠ”ë° ê´œì°®ì€ê°€ìš”?\",\n",
        "    \"ì‹ë‹¹ì„ ìš´ì˜í•˜ëŠ”ë° ì†Œë°©ì‹œì„¤ ì ê²€ì€ ì–¸ì œ ë°›ì•„ì•¼ í•˜ë‚˜ìš”?\",\n",
        "    \"ì˜†ì§‘ì—ì„œ ë¶ˆì´ ë‚¬ëŠ”ë° ì–´ë””ë¡œ ì‹ ê³ í•´ì•¼ í•˜ë‚˜ìš”?\",\n",
        "    \"ì†Œë°©ì°¨ ì „ìš© ì£¼ì°¨êµ¬ì—­ì— ì°¨ë¥¼ ì„¸ì› ë‹¤ê°€ ê³¼íƒœë£Œ ë¶€ê³¼ í†µë³´ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.\",\n",
        "]\n",
        "\n",
        "# ------------------------------------\n",
        "# 1-1. ê¸°ë³¸ API í˜¸ì¶œ\n",
        "# ------------------------------------\n",
        "\n",
        "def classify_complaint_basic(text: str) -> str:\n",
        "    \"\"\"\n",
        "    ë¯¼ì›ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜í•˜ëŠ” ê¸°ë³¸ í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"ë‹¹ì‹ ì€ ì†Œë°©ì²­ ë¯¼ì› ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "ë¯¼ì›ì„ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:\n",
        "1. í™”ì¬ì‹ ê³ /ëŒ€ì‘\n",
        "2. ì†Œë°©ì‹œì„¤ ì ê²€/ì„¤ì¹˜\n",
        "3. ë²•ê·œ ìœ„ë°˜/ê³¼íƒœë£Œ\n",
        "4. ì¼ë°˜ ë¬¸ì˜\n",
        "\n",
        "ì¹´í…Œê³ ë¦¬ì™€ ê°„ë‹¨í•œ ì´ìœ ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.\"\"\"\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n[ê¸°ë³¸ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸]\")\n",
        "test_complaint = sample_complaints[0]\n",
        "print(f\"ë¯¼ì›: {test_complaint}\")\n",
        "print(f\"ë¶„ë¥˜ ê²°ê³¼:\\n{classify_complaint_basic(test_complaint)}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUCyNFbSR6Ij"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------------\n",
        "# 1-2. ì˜¨ë„(Temperature) ë¹„êµ ì‹¤ìŠµ\n",
        "# ------------------------------------\n",
        "\n",
        "print(\"\\n[ì‹¤ìŠµ 1-2] Temperature ë¹„êµ\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "def compare_temperature(text: str):\n",
        "    \"\"\"\n",
        "    ë™ì¼ ì§ˆë¬¸ì— ëŒ€í•´ ì˜¨ë„ë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì •í•˜ì—¬ ì‘ë‹µ ë¹„êµ\n",
        "    \"\"\"\n",
        "    temperatures = [0.0, 0.5, 1.0]\n",
        "\n",
        "    for temp in temperatures:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"ì†Œë°© ë¯¼ì›ì„ ë¶„ë¥˜í•˜ì„¸ìš”.\"},\n",
        "                {\"role\": \"user\", \"content\": text}\n",
        "            ],\n",
        "            temperature=temp,\n",
        "            max_tokens=100\n",
        "        )\n",
        "        print(f\"\\nTemperature = {temp}\")\n",
        "        print(f\"ì‘ë‹µ: {response.choices[0].message.content}\")\n",
        "        print(f\"í† í° ì‚¬ìš©: {response.usage.total_tokens}\")\n",
        "\n",
        "# ì‹¤í–‰\n",
        "compare_temperature(\"ì†Œí™”ê¸° ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_sElnKESBeg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------------\n",
        "# 1-3. í† í° ì œí•œ ì‹¤ìŠµ\n",
        "# ------------------------------------\n",
        "\n",
        "print(\"\\n\\n[ì‹¤ìŠµ 1-3] Max Tokens ë¹„êµ\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "def compare_max_tokens(text: str):\n",
        "    \"\"\"\n",
        "    í† í° ì œí•œì— ë”°ë¥¸ ì‘ë‹µ ì°¨ì´ í™•ì¸\n",
        "    \"\"\"\n",
        "    token_limits = [50, 150, 500]\n",
        "\n",
        "    for max_tok in token_limits:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"ì†Œë°© ë¯¼ì›ì„ ìƒì„¸íˆ ë¶„ë¥˜í•˜ê³  ì²˜ë¦¬ ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.\"},\n",
        "                {\"role\": \"user\", \"content\": text}\n",
        "            ],\n",
        "            temperature=0.5,\n",
        "            max_tokens=max_tok\n",
        "        )\n",
        "        print(f\"\\nMax Tokens = {max_tok}\")\n",
        "        print(f\"ì‘ë‹µ ê¸¸ì´: {len(response.choices[0].message.content)} ë¬¸ì\")\n",
        "        print(f\"ì‘ë‹µ: {response.choices[0].message.content[:200]}...\")\n",
        "\n",
        "# ì‹¤í–‰\n",
        "compare_max_tokens(\"ì•„íŒŒíŠ¸ ë³µë„ ì†Œí™”ê¸° ì„¤ì¹˜ ê¸°ì¤€ê³¼ ìœ„ë°˜ ì‹œ ì²˜ë¦¬ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s19SxJ4bSLhl"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------------\n",
        "# 1-4. ìŠ¤íŠ¸ë¦¬ë° vs ì¼ë°˜ ì‘ë‹µ\n",
        "# ------------------------------------\n",
        "\n",
        "print(\"\\n\\n[ì‹¤ìŠµ 1-4] ìŠ¤íŠ¸ë¦¬ë° vs ì¼ë°˜ ì‘ë‹µ ì†ë„ ë¹„êµ\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# ì¼ë°˜ ì‘ë‹µ\n",
        "start = time.time()\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"ì†Œë°©ì‹œì„¤ ì ê²€ ì£¼ê¸°ë¥¼ ì„¤ëª…í•˜ì„¸ìš”\"}],\n",
        "    stream=False\n",
        ")\n",
        "normal_time = time.time() - start\n",
        "print(f\"[ì¼ë°˜ ì‘ë‹µ] ì†Œìš” ì‹œê°„: {normal_time:.2f}ì´ˆ\")\n",
        "print(f\"ì‘ë‹µ: {response.choices[0].message.content}\\n\")\n",
        "\n",
        "# ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ\n",
        "print(\"[ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ]\")\n",
        "start = time.time()\n",
        "stream = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"ì†Œë°©ì‹œì„¤ ì ê²€ ì£¼ê¸°ë¥¼ ì„¤ëª…í•˜ì„¸ìš”\"}],\n",
        "    stream=True\n",
        ")\n",
        "for chunk in stream:\n",
        "    if chunk.choices[0].delta.content:\n",
        "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
        "stream_time = time.time() - start\n",
        "print(f\"\\n\\n[ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ] ì†Œìš” ì‹œê°„: {stream_time:.2f}ì´ˆ\")\n",
        "print(f\"ì°¸ê³ : ìŠ¤íŠ¸ë¦¬ë°ì´ ë” ë¹ ë¥´ê²Œ ëŠê»´ì§‘ë‹ˆë‹¤!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbbNh85wSXD0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------------\n",
        "# 1-5. ìµœì¢… ë¶„ë¥˜ í•¨ìˆ˜ (Lab 2-5ì—ì„œ ì¬ì‚¬ìš©)\n",
        "# ------------------------------------\n",
        "\n",
        "def classify_complaint(text: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    ë¯¼ì› ë¶„ë¥˜ - êµ¬ì¡°í™”ëœ ê²°ê³¼ ë°˜í™˜\n",
        "    Lab 2-5ì—ì„œ ì¬ì‚¬ìš©í•  í•µì‹¬ í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"ì†Œë°© ë¯¼ì›ì„ ë¶„ë¥˜í•˜ê³  ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:\n",
        "\n",
        "ì¹´í…Œê³ ë¦¬: [í™”ì¬ì‹ ê³ /ì†Œë°©ì‹œì„¤/ë²•ê·œìœ„ë°˜/ì¼ë°˜ë¬¸ì˜]\n",
        "ê¸´ê¸‰ë„: [ë†’ìŒ/ë³´í†µ/ë‚®ìŒ]\n",
        "í‚¤ì›Œë“œ: [í•µì‹¬ í‚¤ì›Œë“œ 3ê°œ]\n",
        "ìš”ì•½: [í•œ ì¤„ ìš”ì•½]\"\"\"\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=200\n",
        "    )\n",
        "\n",
        "    result_text = response.choices[0].message.content\n",
        "\n",
        "    # íŒŒì‹±\n",
        "    lines = result_text.strip().split('\\n')\n",
        "    result = {\n",
        "        \"ì›ë¬¸\": text,\n",
        "        \"ë¶„ë¥˜_ê²°ê³¼\": result_text,\n",
        "        \"ì „ì²´_ì‘ë‹µ\": result_text\n",
        "    }\n",
        "\n",
        "    return result\n",
        "\n",
        "# ì „ì²´ ìƒ˜í”Œ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n\\n[Lab 1 ìµœì¢…] ëª¨ë“  ìƒ˜í”Œ ë¶„ë¥˜\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, complaint in enumerate(sample_complaints, 1):\n",
        "    print(f\"\\n{i}. ë¯¼ì›: {complaint}\")\n",
        "    result = classify_complaint(complaint)\n",
        "    print(f\"ë¶„ë¥˜:\\n{result['ë¶„ë¥˜_ê²°ê³¼']}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "print(\"\\n[ì™„ë£Œ] Lab 1 ì™„ë£Œ! classify_complaint() í•¨ìˆ˜ëŠ” Lab 2-5ì—ì„œ ê³„ì† ì‚¬ìš©ë©ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ-rlJjASl3B"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================\n",
        "# Lab 2: RAG ê¸°ì´ˆ - ì†Œë°©ê¸°ë³¸ë²• (40ë¶„)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"[Lab 2] RAG ê¸°ì´ˆ - ì†Œë°©ê¸°ë³¸ë²• ê²€ìƒ‰\")\n",
        "print(\"=\"*60)\n",
        "# í•œê¸€ ì²˜ë¦¬ ì„¤ì •\n",
        "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\"\n",
        "\n",
        "# ------------------------------------\n",
        "# 2-1. PDF ì½ê¸° ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "# ------------------------------------\n",
        "def extract_text_from_pdf(pdf_path, max_pages=None):\n",
        "    pages_data = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        total_pages = len(pdf.pages) if max_pages is None else min(max_pages, len(pdf.pages))\n",
        "        for i in range(total_pages):\n",
        "            text = pdf.pages[i].extract_text()\n",
        "            pages_data.append({\n",
        "                \"page_num\": i + 1,\n",
        "                \"text\": text,\n",
        "                \"char_count\": len(text)\n",
        "            })\n",
        "    return pages_data\n",
        "\n",
        "# ì†Œë°©ê¸°ë³¸ë²• ì½ê¸°\n",
        "print(\"\\n[ì§„í–‰ì¤‘] ì†Œë°©ê¸°ë³¸ë²•_28ì¡°.pdf ì½ê¸°...\")\n",
        "#fire_law_pages = extract_text_from_pdf(\"ì†Œë°©ê¸°ë³¸ë²•_28ì¡°.pdf\", max_pages=10)\n",
        "fire_law_pages = extract_text_from_pdf(\"ì†Œë°©ê¸°ë³¸ë²•_28ì¡°.pdf\", max_pages=None)\n",
        "max_pages={len(fire_law_pages)}\n",
        "print(f\"[ì™„ë£Œ] ì´ {len(fire_law_pages)} í˜ì´ì§€ ì¶”ì¶œ\")\n",
        "print(f\"\\n[ìƒ˜í”Œ] 1í˜ì´ì§€ ìƒ˜í”Œ (ì²˜ìŒ 300ì):\")\n",
        "print(fire_law_pages[0]['text'][:300])\n",
        "\n",
        "# ------------------------------------\n",
        "# 2-2. í…ìŠ¤íŠ¸ ì²­í‚¹ (Chunking)\n",
        "# ------------------------------------\n",
        "\n",
        "def chunk_text(pages_data: List[Dict], chunk_size: int = 500, overlap: int = 50) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• \n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    chunk_id = 0\n",
        "\n",
        "    for page_data in pages_data:\n",
        "        text = page_data['text']\n",
        "        page_num = page_data['page_num']\n",
        "\n",
        "        # ê°„ë‹¨í•œ ì²­í‚¹ (ë¬¸ì ê¸°ë°˜)\n",
        "        start = 0\n",
        "        while start < len(text):\n",
        "            end = start + chunk_size\n",
        "            chunk_text = text[start:end]\n",
        "\n",
        "            if chunk_text.strip():  # ë¹ˆ ì²­í¬ ì œì™¸\n",
        "                chunks.append({\n",
        "                    \"id\": f\"law_chunk_{chunk_id}\",\n",
        "                    \"text\": chunk_text,\n",
        "                    \"page\": page_num,\n",
        "                    \"start_pos\": start\n",
        "                })\n",
        "                chunk_id += 1\n",
        "\n",
        "            start = end - overlap\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# ì²­í‚¹ ì‹¤í–‰\n",
        "print(\"\\n[ì§„í–‰ì¤‘] í…ìŠ¤íŠ¸ ì²­í‚¹ ì¤‘...\")\n",
        "law_chunks = chunk_text(fire_law_pages, chunk_size=500, overlap=50)\n",
        "\n",
        "print(f\"[ì™„ë£Œ] ì´ {len(law_chunks)}ê°œ ì²­í¬ ìƒì„±\")\n",
        "print(f\"\\n[ìƒ˜í”Œ] ì²« ë²ˆì§¸ ì²­í¬:\")\n",
        "print(f\"ID: {law_chunks[0]['id']}\")\n",
        "print(f\"í˜ì´ì§€: {law_chunks[0]['page']}\")\n",
        "print(f\"ë‚´ìš©: {law_chunks[0]['text'][:200]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlcmbO1RSzgb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------------\n",
        "# 2-3. ì„ë² ë”© ìƒì„±\n",
        "# ------------------------------------\n",
        "\n",
        "def get_embedding(text: str) -> List[float]:\n",
        "    \"\"\"\n",
        "    í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
        "    \"\"\"\n",
        "    response = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=text\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# ìƒ˜í”Œ ì„ë² ë”© í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n[ì§„í–‰ì¤‘] ì„ë² ë”© í…ŒìŠ¤íŠ¸...\")\n",
        "sample_text = \"ì†Œë°©ì‹œì„¤ ì„¤ì¹˜ ê¸°ì¤€\"\n",
        "sample_embedding = get_embedding(sample_text)\n",
        "print(f\"[ì™„ë£Œ] ì„ë² ë”© ì°¨ì›: {len(sample_embedding)}\")\n",
        "print(f\"ìƒ˜í”Œ ë²¡í„° (ì²˜ìŒ 5ê°œ): {sample_embedding[:5]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rs3xizLUNI7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------------\n",
        "# 2-4. ChromaDBì— ì €ì¥\n",
        "# ------------------------------------\n",
        "\n",
        "print(\"\\n[ì§„í–‰ì¤‘] ChromaDB ìƒì„± ì¤‘...\")\n",
        "\n",
        "# ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
        "chroma_client = chromadb.Client(Settings(\n",
        "    persist_directory=\"./chroma_db\",\n",
        "    anonymized_telemetry=False\n",
        "))\n",
        "\n",
        "# ì»¬ë ‰ì…˜ ìƒì„± (ê¸°ì¡´ ê²ƒ ì‚­ì œ í›„)\n",
        "try:\n",
        "    chroma_client.delete_collection(\"fire_law\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "fire_law_collection = chroma_client.create_collection(\n",
        "    name=\"fire_law\",\n",
        "    metadata={\"description\": \"ì†Œë°©ê¸°ë³¸ë²•\"}\n",
        ")\n",
        "\n",
        "# ì²­í¬ ì„ë² ë”© ë° ì €ì¥\n",
        "print(\"[ì§„í–‰ì¤‘] ì²­í¬ ì„ë² ë”© ë° ì €ì¥ ì¤‘...\")\n",
        "for i, chunk in enumerate(law_chunks):\n",
        "    if i % 10 == 0:\n",
        "        print(f\"  ì§„í–‰: {i}/{len(law_chunks)}\")\n",
        "\n",
        "    embedding = get_embedding(chunk['text'])\n",
        "\n",
        "    fire_law_collection.add(\n",
        "        ids=[chunk['id']],\n",
        "        embeddings=[embedding],\n",
        "        documents=[chunk['text']],\n",
        "        metadatas=[{\n",
        "            \"page\": chunk['page'],\n",
        "            \"source\": \"ì†Œë°©ê¸°ë³¸ë²•\"\n",
        "        }]\n",
        "    )\n",
        "\n",
        "print(f\"[ì™„ë£Œ] {len(law_chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvfU19GGUS3k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------------\n",
        "# 2-5. RAG ê²€ìƒ‰ í•¨ìˆ˜ (Lab 4ì—ì„œ ì¬ì‚¬ìš©)\n",
        "# ------------------------------------\n",
        "\n",
        "def search_fire_law(query: str, n_results: int = 3) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    ì†Œë°©ê¸°ë³¸ë²• ê²€ìƒ‰ í•¨ìˆ˜\n",
        "    Lab 4ì—ì„œ ë³´ê³ ì„œ ìƒì„± ì‹œ ì¬ì‚¬ìš©\n",
        "    \"\"\"\n",
        "    query_embedding = get_embedding(query)\n",
        "\n",
        "    results = fire_law_collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=n_results\n",
        "    )\n",
        "\n",
        "    search_results = []\n",
        "    for i in range(len(results['documents'][0])):\n",
        "        search_results.append({\n",
        "            \"text\": results['documents'][0][i],\n",
        "            \"page\": results['metadatas'][0][i]['page'],\n",
        "            \"source\": results['metadatas'][0][i]['source']\n",
        "        })\n",
        "\n",
        "    return search_results\n",
        "\n",
        "# ------------------------------------\n",
        "# 2-6. RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±\n",
        "# ------------------------------------\n",
        "\n",
        "def answer_with_rag(question: str) -> str:\n",
        "    \"\"\"\n",
        "    ì§ˆë¬¸ -> ê²€ìƒ‰ -> ë‹µë³€ ìƒì„±\n",
        "    \"\"\"\n",
        "    # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰\n",
        "    search_results = search_fire_law(question, n_results=3)\n",
        "\n",
        "    # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
        "    context = \"\\n\\n\".join([\n",
        "        f\"[ì¶œì²˜: {r['source']}, {r['page']}í˜ì´ì§€]\\n{r['text']}\"\n",
        "        for r in search_results\n",
        "    ])\n",
        "\n",
        "    # 3. LLMì—ê²Œ ë‹µë³€ ìš”ì²­\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"ë‹¹ì‹ ì€ ì†Œë°©ë²•ë ¹ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
        "ì œê³µëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n",
        "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ \"ì œê³µëœ ìë£Œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³  í•˜ì„¸ìš”.\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n",
        "\n",
        "[ì°¸ê³  ë¬¸ì„œ]\n",
        "{context}\n",
        "\n",
        "[ì§ˆë¬¸]\n",
        "{question}\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n\\n[Lab 2 ìµœì¢…] RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_questions = [\n",
        "    \"ì†Œë°©ì‹œì„¤ ì„¤ì¹˜ ëŒ€ìƒì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?\",\n",
        "    \"ì†Œë°©ì‹œì„¤ ì ê²€ì€ ì–¸ì œ í•´ì•¼ í•˜ë‚˜ìš”?\",\n",
        "    \"ìœ„ë°˜ ì‹œ ê³¼íƒœë£ŒëŠ” ì–¼ë§ˆì¸ê°€ìš”?\"\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    print(f\"\\n[ì§ˆë¬¸] {q}\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    # ê²€ìƒ‰ ê²°ê³¼ í™•ì¸\n",
        "    results = search_fire_law(q, n_results=2)\n",
        "    print(\"[ê²€ìƒ‰ëœ ë¬¸ì„œ]\")\n",
        "    for i, r in enumerate(results, 1):\n",
        "        print(f\"  {i}. {r['source']} {r['page']}í˜ì´ì§€\")\n",
        "        print(f\"     {r['text'][:150]}...\")\n",
        "\n",
        "    # ë‹µë³€ ìƒì„±\n",
        "    print(\"\\n[ë‹µë³€]\")\n",
        "    answer = answer_with_rag(q)\n",
        "    print(answer)\n",
        "    print(\"=\"*60)\n",
        "\n",
        "print(\"\\n[ì™„ë£Œ] Lab 2 ì™„ë£Œ! search_fire_law() í•¨ìˆ˜ëŠ” Lab 4ì—ì„œ ì¬ì‚¬ìš©ë©ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HlkvPY9VYfq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================\n",
        "# Lab 3: ê³ ê¸‰ ê²€ìƒ‰ - í™”ì¬ì˜ˆë°© (40ë¶„)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"[Lab 3] ê³ ê¸‰ ê²€ìƒ‰ - í™”ì¬ì˜ˆë°© ê°€ì´ë“œ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ------------------------------------\n",
        "# 3-1. í™”ì¬ì˜ˆë°© PDF ì²˜ë¦¬\n",
        "# ------------------------------------\n",
        "\n",
        "print(\"\\n[ì§„í–‰ì¤‘] í™”ì¬ì˜ˆë°©.pdf ì½ê¸°...\")\n",
        "prevention_pages = extract_text_from_pdf(\"í™”ì¬ì˜ˆë°©.pdf\")\n",
        "\n",
        "print(f\"[ì™„ë£Œ] ì´ {len(prevention_pages)} í˜ì´ì§€ ì¶”ì¶œ\")\n",
        "\n",
        "# ì²­í‚¹\n",
        "print(\"\\n[ì§„í–‰ì¤‘] í…ìŠ¤íŠ¸ ì²­í‚¹ ì¤‘...\")\n",
        "prevention_chunks = chunk_text(prevention_pages, chunk_size=500, overlap=50)\n",
        "print(f\"[ì™„ë£Œ] ì´ {len(prevention_chunks)}ê°œ ì²­í¬ ìƒì„±\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQpG8qhbV5gw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------------\n",
        "# 3-2. ë‘ ë²ˆì§¸ ì»¬ë ‰ì…˜ ìƒì„±\n",
        "# ------------------------------------\n",
        "\n",
        "print(\"\\n[ì§„í–‰ì¤‘] í™”ì¬ì˜ˆë°© ChromaDB ìƒì„± ì¤‘...\")\n",
        "\n",
        "try:\n",
        "    chroma_client.delete_collection(\"fire_prevention\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "prevention_collection = chroma_client.create_collection(\n",
        "    name=\"fire_prevention\",\n",
        "    metadata={\"description\": \"í™”ì¬ì˜ˆë°© ê°€ì´ë“œ\"}\n",
        ")\n",
        "\n",
        "# ì €ì¥\n",
        "print(\"[ì§„í–‰ì¤‘] ì²­í¬ ì„ë² ë”© ë° ì €ì¥ ì¤‘...\")\n",
        "for i, chunk in enumerate(prevention_chunks):\n",
        "    if i % 20 == 0:\n",
        "        print(f\"  ì§„í–‰: {i}/{len(prevention_chunks)}\")\n",
        "\n",
        "    embedding = get_embedding(chunk['text'])\n",
        "\n",
        "    prevention_collection.add(\n",
        "        ids=[chunk['id']],\n",
        "        embeddings=[embedding],\n",
        "        documents=[chunk['text']],\n",
        "        metadatas=[{\n",
        "            \"page\": chunk['page'],\n",
        "            \"source\": \"í™”ì¬ì˜ˆë°©ê°€ì´ë“œ\"\n",
        "        }]\n",
        "    )\n",
        "\n",
        "print(f\"[ì™„ë£Œ] {len(prevention_chunks)}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vNZvE-ZV-pZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ------------------------------------\n",
        "# 3-3. í™”ì¬ì˜ˆë°© ê²€ìƒ‰ í•¨ìˆ˜ (Lab 4ì—ì„œ ì¬ì‚¬ìš©)\n",
        "# ------------------------------------\n",
        "\n",
        "def search_fire_prevention(query: str, n_results: int = 3) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    í™”ì¬ì˜ˆë°© ê°€ì´ë“œ ê²€ìƒ‰\n",
        "    Lab 4ì—ì„œ ë³´ê³ ì„œ ìƒì„± ì‹œ ì¬ì‚¬ìš©\n",
        "    \"\"\"\n",
        "    query_embedding = get_embedding(query)\n",
        "\n",
        "    results = prevention_collection.query(\n",
        "        query_embeddings=[query_embedding],\n",
        "        n_results=n_results\n",
        "    )\n",
        "\n",
        "    search_results = []\n",
        "    for i in range(len(results['documents'][0])):\n",
        "        search_results.append({\n",
        "            \"text\": results['documents'][0][i],\n",
        "            \"page\": results['metadatas'][0][i]['page'],\n",
        "            \"source\": results['metadatas'][0][i]['source']\n",
        "        })\n",
        "\n",
        "    return search_results\n",
        "\n",
        "# ------------------------------------\n",
        "# 3-4. í†µí•© ê²€ìƒ‰ (ë²•ë ¹ + ê°€ì´ë“œ)\n",
        "# ------------------------------------\n",
        "\n",
        "def search_both_sources(query: str, n_results_per_source: int = 2) -> Dict:\n",
        "    \"\"\"\n",
        "    ì†Œë°©ê¸°ë³¸ë²• + í™”ì¬ì˜ˆë°© ê°€ì´ë“œ ë™ì‹œ ê²€ìƒ‰\n",
        "    Lab 4ì—ì„œ ë³´ê³ ì„œ ì‘ì„± ì‹œ ì‚¬ìš©\n",
        "    \"\"\"\n",
        "    law_results = search_fire_law(query, n_results_per_source)\n",
        "    prevention_results = search_fire_prevention(query, n_results_per_source)\n",
        "\n",
        "    return {\n",
        "        \"ë²•ë ¹\": law_results,\n",
        "        \"ì˜ˆë°©ê°€ì´ë“œ\": prevention_results,\n",
        "        \"total_count\": len(law_results) + len(prevention_results)\n",
        "    }\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸\n",
        "print(\"\\n\\n[Lab 3 ìµœì¢…] í†µí•© ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_queries = [\n",
        "    \"ì†Œí™”ê¸° ê´€ë¦¬ ë°©ë²•\",\n",
        "    \"í™”ì¬ ë°œìƒ ì‹œ ëŒ€ì‘ ì ˆì°¨\",\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n[ê²€ìƒ‰ì–´] {query}\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    combined_results = search_both_sources(query, n_results_per_source=2)\n",
        "\n",
        "    print(\"\\n[ì†Œë°©ê¸°ë³¸ë²•]\")\n",
        "    for i, r in enumerate(combined_results['ë²•ë ¹'], 1):\n",
        "        print(f\"  {i}. {r['page']}í˜ì´ì§€\")\n",
        "        print(f\"     {r['text'][:120]}...\")\n",
        "\n",
        "    print(\"\\n[í™”ì¬ì˜ˆë°©ê°€ì´ë“œ]\")\n",
        "    for i, r in enumerate(combined_results['ì˜ˆë°©ê°€ì´ë“œ'], 1):\n",
        "        print(f\"  {i}. {r['page']}í˜ì´ì§€\")\n",
        "        print(f\"     {r['text'][:120]}...\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "\n",
        "print(\"\\n[ì™„ë£Œ] Lab 3 ì™„ë£Œ! search_both_sources() í•¨ìˆ˜ëŠ” Lab 4ì—ì„œ ì¬ì‚¬ìš©ë©ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJpYwuy0WQ-y"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================\n",
        "# Lab 4: ë³´ê³ ì„œ ìë™ ìƒì„± (40ë¶„)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"[Lab 4] ë¯¼ì› ì²˜ë¦¬ ë³´ê³ ì„œ ìë™ ìƒì„±\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ------------------------------------\n",
        "# 4-1. ë³´ê³ ì„œ ìƒì„± í•¨ìˆ˜ (Lab 1-3 í†µí•©)\n",
        "# ------------------------------------\n",
        "\n",
        "def generate_complaint_report(complaint_text: str) -> Dict:\n",
        "    \"\"\"\n",
        "    ë¯¼ì› -> ë¶„ë¥˜ -> ê²€ìƒ‰ -> ë³´ê³ ì„œ ìƒì„±\n",
        "    Lab 1, 2, 3ì˜ ëª¨ë“  í•¨ìˆ˜ë¥¼ í™œìš©\n",
        "    \"\"\"\n",
        "    print(\"\\n[ì§„í–‰ì¤‘] ë³´ê³ ì„œ ìƒì„± ì¤‘...\")\n",
        "\n",
        "    # Step 1: ë¯¼ì› ë¶„ë¥˜ (Lab 1)\n",
        "    print(\"  [1ë‹¨ê³„] ë¯¼ì› ë¶„ë¥˜ ì¤‘...\")\n",
        "    classification = classify_complaint(complaint_text)\n",
        "\n",
        "    # Step 2: ê´€ë ¨ ìë£Œ ê²€ìƒ‰ (Lab 2, 3)\n",
        "    print(\"  [2ë‹¨ê³„] ê´€ë ¨ ë²•ë ¹ ë° ê°€ì´ë“œ ê²€ìƒ‰ ì¤‘...\")\n",
        "    search_results = search_both_sources(complaint_text, n_results_per_source=2)\n",
        "\n",
        "    # Step 3: ë³´ê³ ì„œ ë³¸ë¬¸ ìƒì„±\n",
        "    print(\"  [3ë‹¨ê³„] ë³´ê³ ì„œ ì‘ì„± ì¤‘...\")\n",
        "\n",
        "    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±\n",
        "    law_context = \"\\n\".join([\n",
        "        f\"- {r['source']} {r['page']}p: {r['text'][:200]}\"\n",
        "        for r in search_results['ë²•ë ¹']\n",
        "    ])\n",
        "\n",
        "    prevention_context = \"\\n\".join([\n",
        "        f\"- {r['source']} {r['page']}p: {r['text'][:200]}\"\n",
        "        for r in search_results['ì˜ˆë°©ê°€ì´ë“œ']\n",
        "    ])\n",
        "\n",
        "    # LLMìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„±\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"ë‹¹ì‹ ì€ ì†Œë°©ì²­ ë¯¼ì› ì²˜ë¦¬ ë‹´ë‹¹ìì…ë‹ˆë‹¤.\n",
        "ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ê³µì‹ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:\n",
        "\n",
        "ã€ë¯¼ì› ì²˜ë¦¬ ë³´ê³ ì„œã€‘\n",
        "\n",
        "1. ë¯¼ì› ë‚´ìš©\n",
        "   [ë¯¼ì› ìš”ì•½]\n",
        "\n",
        "2. ë¶„ë¥˜ ê²°ê³¼\n",
        "   [ì¹´í…Œê³ ë¦¬, ê¸´ê¸‰ë„ ë“±]\n",
        "\n",
        "3. ê´€ë ¨ ë²•ë ¹ ë° ê·¼ê±°\n",
        "   [ì†Œë°©ê¸°ë³¸ë²• ë‚´ìš©]\n",
        "\n",
        "4. ì²˜ë¦¬ ë°©ì•ˆ\n",
        "   [êµ¬ì²´ì ì¸ ëŒ€ì‘ ë°©ë²•]\n",
        "\n",
        "5. ì˜ˆë°© ê°€ì´ë“œ\n",
        "   [í™”ì¬ì˜ˆë°© ì°¸ê³ ì‚¬í•­]\n",
        "\n",
        "6. ë‹´ë‹¹ ë¶€ì„œ ë° ì²˜ë¦¬ ê¸°í•œ\n",
        "   [ì¶”ì²œ ë¶€ì„œ ë° ê¸°í•œ]\n",
        "\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"ë‹¤ìŒ ë¯¼ì›ì— ëŒ€í•œ ì²˜ë¦¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
        "\n",
        "[ë¯¼ì› ë‚´ìš©]\n",
        "{complaint_text}\n",
        "\n",
        "[ë¶„ë¥˜ ì •ë³´]\n",
        "{classification['ë¶„ë¥˜_ê²°ê³¼']}\n",
        "\n",
        "[ì°¸ê³  - ì†Œë°©ê¸°ë³¸ë²•]\n",
        "{law_context}\n",
        "\n",
        "[ì°¸ê³  - í™”ì¬ì˜ˆë°© ê°€ì´ë“œ]\n",
        "{prevention_context}\n",
        "\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.4,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    report = response.choices[0].message.content\n",
        "\n",
        "    print(\"  [ì™„ë£Œ] ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!\")\n",
        "\n",
        "    return {\n",
        "        \"ë¯¼ì›ì›ë¬¸\": complaint_text,\n",
        "        \"ë¶„ë¥˜\": classification,\n",
        "        \"ë²•ë ¹ê²€ìƒ‰\": search_results['ë²•ë ¹'],\n",
        "        \"ì˜ˆë°©ê²€ìƒ‰\": search_results['ì˜ˆë°©ê°€ì´ë“œ'],\n",
        "        \"ë³´ê³ ì„œ\": report\n",
        "    }\n",
        "\n",
        "# ------------------------------------\n",
        "# 4-2. ë³´ê³ ì„œ ìƒì„± í…ŒìŠ¤íŠ¸\n",
        "# ------------------------------------\n",
        "\n",
        "print(\"\\n\\n[Lab 4 ìµœì¢…] ë³´ê³ ì„œ ìƒì„± í…ŒìŠ¤íŠ¸\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_complaints_for_report = [\n",
        "    \"ìƒê°€ ê±´ë¬¼ ë³µë„ì— ì†Œí™”ê¸°ê°€ ì—†ê³ , ë¹„ìƒêµ¬ë„ ì§ìœ¼ë¡œ ë§‰í˜€ìˆìŠµë‹ˆë‹¤. ì•ˆì „ ì ê²€ì„ ìš”ì²­í•©ë‹ˆë‹¤.\",\n",
        "    \"ìŒì‹ì ì„ ìƒˆë¡œ ì—´ë ¤ê³  í•˜ëŠ”ë° ì†Œë°©ì‹œì„¤ì„ ì–´ë–»ê²Œ ì„¤ì¹˜í•´ì•¼ í•˜ë‚˜ìš”?\"\n",
        "]\n",
        "\n",
        "for i, complaint in enumerate(test_complaints_for_report, 1):\n",
        "    print(f\"\\n\\n{'='*60}\")\n",
        "    print(f\"[í…ŒìŠ¤íŠ¸ {i}]\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"ë¯¼ì›: {complaint}\\n\")\n",
        "\n",
        "    result = generate_complaint_report(complaint)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"[ìƒì„±ëœ ë³´ê³ ì„œ]\")\n",
        "    print(\"=\"*60)\n",
        "    print(result['ë³´ê³ ì„œ'])\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "print(\"\\n[ì™„ë£Œ] Lab 4 ì™„ë£Œ! generate_complaint_report() í•¨ìˆ˜ëŠ” Lab 5ì—ì„œ UIì— ì—°ê²°ë©ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pfAUFxaWbIG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================\n",
        "# Lab 5: Gradio UI + ìµœì¢… í†µí•© (40ë¶„)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"[Lab 5] Gradio UI êµ¬ì¶• ë° ìµœì¢… ì™„ì„±\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ------------------------------------\n",
        "# 5-1. Gradio UI í•¨ìˆ˜\n",
        "# ------------------------------------\n",
        "\n",
        "def process_complaint_ui(complaint_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Gradio UIìš© ë˜í¼ í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    if not complaint_text.strip():\n",
        "        return \"[ê²½ê³ ] ë¯¼ì› ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\"\n",
        "\n",
        "    try:\n",
        "        result = generate_complaint_report(complaint_text)\n",
        "        return result['ë³´ê³ ì„œ']\n",
        "    except Exception as e:\n",
        "        return f\"[ì˜¤ë¥˜ ë°œìƒ] {str(e)}\"\n",
        "\n",
        "# ------------------------------------\n",
        "# 5-2. Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì¶•\n",
        "# ------------------------------------\n",
        "\n",
        "# ì˜ˆì‹œ ë¯¼ì›ë“¤\n",
        "examples = [\n",
        "    [\"ì•„íŒŒíŠ¸ ë³µë„ì— ì†Œí™”ê¸°ê°€ ì—†ëŠ”ë° ê´œì°®ì€ê°€ìš”?\"],\n",
        "    [\"ì‹ë‹¹ì„ ìš´ì˜í•˜ëŠ”ë° ì†Œë°©ì‹œì„¤ ì ê²€ì€ ì–¸ì œ ë°›ì•„ì•¼ í•˜ë‚˜ìš”?\"],\n",
        "    [\"ì†Œë°©ì°¨ ì „ìš©êµ¬ì—­ì— ì£¼ì°¨í–ˆë‹¤ê°€ ê³¼íƒœë£Œë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.\"],\n",
        "]\n",
        "\n",
        "# Gradio ì¸í„°í˜ì´ìŠ¤\n",
        "interface = gr.Interface(\n",
        "    fn=process_complaint_ui,\n",
        "    inputs=gr.Textbox(\n",
        "        label=\"ë¯¼ì› ë‚´ìš©\",\n",
        "        placeholder=\"ì²˜ë¦¬í•  ë¯¼ì› ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”...\",\n",
        "        lines=5\n",
        "    ),\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"ì²˜ë¦¬ ë³´ê³ ì„œ\",\n",
        "        lines=20\n",
        "    ),\n",
        "    title=\"ì†Œë°©ì²­ ë¯¼ì›ì²˜ë¦¬ AI Agent\",\n",
        "    description=\"\"\"\n",
        "    **ë¯¼ì› ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:**\n",
        "    1. ë¯¼ì› ìë™ ë¶„ë¥˜\n",
        "    2. ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰ (ì†Œë°©ê¸°ë³¸ë²•)\n",
        "    3. ì˜ˆë°© ê°€ì´ë“œ ê²€ìƒ‰ (í™”ì¬ì˜ˆë°©)\n",
        "    4. ê³µì‹ ì²˜ë¦¬ ë³´ê³ ì„œ ìƒì„±\n",
        "\n",
        "    ì•„ë˜ ì˜ˆì‹œë¥¼ í´ë¦­í•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•´ë³´ì„¸ìš”!\n",
        "    \"\"\",\n",
        "    examples=examples,\n",
        "    theme=gr.themes.Soft()\n",
        ")\n",
        "\n",
        "# ------------------------------------\n",
        "# 5-3. UI ì‹¤í–‰\n",
        "# ------------------------------------\n",
        "\n",
        "print(\"\\n[ì‹¤í–‰ì¤‘] Gradio UI ì‹¤í–‰ ì¤‘...\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"[ì™„ë£Œ] ëª¨ë“  Lab ì™„ë£Œ!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "í•™ìŠµ ë‚´ìš© ì •ë¦¬:\n",
        "  Lab 1: OpenAI API ì‚¬ìš©ë²• + ë¯¼ì› ë¶„ë¥˜\n",
        "  Lab 2: RAG ê¸°ì´ˆ + ì†Œë°©ê¸°ë³¸ë²• ê²€ìƒ‰\n",
        "  Lab 3: ë‹¤ì¤‘ ë¬¸ì„œ ê²€ìƒ‰ + í™”ì¬ì˜ˆë°© ê°€ì´ë“œ\n",
        "  Lab 4: í†µí•© ë³´ê³ ì„œ ìë™ ìƒì„±\n",
        "  Lab 5: Gradio UI êµ¬ì¶•\n",
        "\n",
        "ì´ì œ ì‹¤ì „ ë¯¼ì›ì„ ì²˜ë¦¬í•´ë³´ì„¸ìš”!\n",
        "\"\"\")\n",
        "\n",
        "# Gradio ì‹¤í–‰\n",
        "interface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
