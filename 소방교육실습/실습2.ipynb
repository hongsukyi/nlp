{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a73bde-f06c-45f1-8ed7-8f9a2a3dbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 2: RAG 기초 - 소방기본법 검색 (40분) - 실습 버전\n",
    "# 소방청 민원처리 AI Agent 교육\n",
    "\n",
    "\"\"\"\n",
    "학습 목표:\n",
    "- RAG(Retrieval Augmented Generation) 개념 이해\n",
    "- PDF 텍스트 추출 및 청킹\n",
    "- 임베딩과 벡터 검색\n",
    "- ChromaDB 사용법\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# 환경 설정\n",
    "# ============================================================\n",
    "\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install openai chromadb pdfplumber -q\n",
    "\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "import pdfplumber\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from typing import List, Dict\n",
    "\n",
    "# API 키 설정\n",
    "print(\"[API 키 입력] OpenAI API 키를 입력하세요\")\n",
    "api_key = getpass.getpass(\"API Key: \")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(\"[완료] 환경 설정 완료!\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# PDF 파일 업로드\n",
    "# ============================================================\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"[파일 업로드] 소방기본법.pdf (10페이지)를 업로드하세요\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"[완료] {filename} 업로드 완료\")\n",
    "\n",
    "# ============================================================\n",
    "# Lab 1 함수 재사용 (이미 구현됨)\n",
    "# ============================================================\n",
    "\n",
    "def classify_complaint(text: str) -> Dict[str, str]:\n",
    "    \"\"\"Lab 1에서 만든 민원 분류 함수\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"소방 민원을 분류하고 다음 형식으로 답변하세요:\n",
    "\n",
    "카테고리: [화재신고/소방시설/법규위반/일반문의]\n",
    "긴급도: [높음/보통/낮음]\n",
    "키워드: [핵심 키워드 3개]\n",
    "요약: [한 줄 요약]\"\"\"\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "        max_tokens=200\n",
    "    )\n",
    "    \n",
    "    result_text = response.choices[0].message.content\n",
    "    \n",
    "    return {\n",
    "        \"원문\": text,\n",
    "        \"분류_결과\": result_text\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# 실습 1: PDF 텍스트 추출\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[실습 1] PDF 텍스트 추출\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str, max_pages: int = None) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    PDF에서 텍스트 추출 (페이지별)\n",
    "    \n",
    "    TODO: pdfplumber를 사용하여 PDF 텍스트 추출하기\n",
    "    \n",
    "    힌트:\n",
    "    1. pdfplumber.open(pdf_path) 사용\n",
    "    2. with 문으로 PDF 열기\n",
    "    3. pdf.pages로 페이지 접근\n",
    "    4. page.extract_text()로 텍스트 추출\n",
    "    5. 각 페이지별로 딕셔너리 생성\n",
    "    \n",
    "    반환 형식:\n",
    "    [\n",
    "        {\"page_num\": 1, \"text\": \"...\", \"char_count\": 1000},\n",
    "        {\"page_num\": 2, \"text\": \"...\", \"char_count\": 950},\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    pages_data = []\n",
    "    \n",
    "    # TODO: pdfplumber로 PDF 열기\n",
    "    # with pdfplumber.open(pdf_path) as pdf:\n",
    "    #     total_pages = ...\n",
    "    #     for i in range(total_pages):\n",
    "    #         page = pdf.pages[i]\n",
    "    #         text = page.extract_text()\n",
    "    #         pages_data.append({...})\n",
    "    \n",
    "    return pages_data\n",
    "\n",
    "# PDF 읽기 테스트\n",
    "print(\"\\n[테스트]\")\n",
    "fire_law_pages = extract_text_from_pdf(\"소방기본법.pdf\", max_pages=10)\n",
    "\n",
    "if fire_law_pages:\n",
    "    print(f\"[완료] 총 {len(fire_law_pages)} 페이지 추출\")\n",
    "    print(f\"\\n[샘플] 1페이지 내용 (처음 300자):\")\n",
    "    print(fire_law_pages[0]['text'][:300])\n",
    "    print(\"...\")\n",
    "else:\n",
    "    print(\"[아직 구현되지 않았습니다]\")\n",
    "\n",
    "# ============================================================\n",
    "# 실습 2: 텍스트 청킹 (Chunking)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"[실습 2] 텍스트 청킹 - 작은 단위로 분할\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def chunk_text(pages_data: List[Dict], chunk_size: int = 500, overlap: int = 50) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    텍스트를 작은 청크로 분할\n",
    "    \n",
    "    TODO: 슬라이딩 윈도우 방식으로 텍스트 청킹하기\n",
    "    \n",
    "    왜 청킹이 필요한가?\n",
    "    - 전체 문서는 너무 길어서 검색 정확도가 떨어짐\n",
    "    - 작은 단위로 나누면 관련 부분만 정확히 찾을 수 있음\n",
    "    \n",
    "    힌트:\n",
    "    1. 각 페이지의 텍스트를 chunk_size만큼 자르기\n",
    "    2. start 위치를 overlap만큼 겹치게 이동\n",
    "    3. 각 청크에 고유 ID, 페이지 번호 저장\n",
    "    \n",
    "    반환 형식:\n",
    "    [\n",
    "        {\"id\": \"law_chunk_0\", \"text\": \"...\", \"page\": 1, \"start_pos\": 0},\n",
    "        {\"id\": \"law_chunk_1\", \"text\": \"...\", \"page\": 1, \"start_pos\": 450},\n",
    "        ...\n",
    "    ]\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    chunk_id = 0\n",
    "    \n",
    "    for page_data in pages_data:\n",
    "        text = page_data['text']\n",
    "        page_num = page_data['page_num']\n",
    "        \n",
    "        # TODO: 슬라이딩 윈도우로 청킹하기\n",
    "        # start = 0\n",
    "        # while start < len(text):\n",
    "        #     end = start + chunk_size\n",
    "        #     chunk_text = text[start:end]\n",
    "        #     if chunk_text.strip():\n",
    "        #         chunks.append({...})\n",
    "        #         chunk_id += 1\n",
    "        #     start = end - overlap\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# 청킹 테스트\n",
    "if fire_law_pages:\n",
    "    print(\"\\n[테스트]\")\n",
    "    law_chunks = chunk_text(fire_law_pages, chunk_size=500, overlap=50)\n",
    "    \n",
    "    if law_chunks:\n",
    "        print(f\"[완료] 총 {len(law_chunks)}개 청크 생성\")\n",
    "        print(f\"\\n[샘플] 첫 번째 청크:\")\n",
    "        print(f\"ID: {law_chunks[0]['id']}\")\n",
    "        print(f\"페이지: {law_chunks[0]['page']}\")\n",
    "        print(f\"길이: {len(law_chunks[0]['text'])} 문자\")\n",
    "        print(f\"내용: {law_chunks[0]['text'][:200]}...\")\n",
    "    else:\n",
    "        print(\"[아직 구현되지 않았습니다]\")\n",
    "else:\n",
    "    print(\"[PDF를 먼저 읽어야 합니다]\")\n",
    "    law_chunks = []\n",
    "\n",
    "# ============================================================\n",
    "# 실습 3: 임베딩 생성\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"[실습 3] 임베딩 - 텍스트를 숫자 벡터로 변환\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    텍스트를 벡터로 변환\n",
    "    \n",
    "    TODO: OpenAI Embeddings API 호출하기\n",
    "    \n",
    "    임베딩이란?\n",
    "    - 텍스트를 의미를 담은 숫자 배열로 변환\n",
    "    - 의미가 비슷한 텍스트는 비슷한 숫자 배열을 가짐\n",
    "    \n",
    "    힌트:\n",
    "    - client.embeddings.create() 사용\n",
    "    - model: \"text-embedding-3-small\"\n",
    "    - input: text\n",
    "    - 반환: response.data[0].embedding\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: 여기에 Embeddings API 호출 코드 작성\n",
    "    # response = client.embeddings.create(...)\n",
    "    # return response.data[0].embedding\n",
    "    \n",
    "    return []\n",
    "\n",
    "# 임베딩 테스트\n",
    "print(\"\\n[테스트 1] 단어 임베딩\")\n",
    "sample_text = \"소방시설 설치 기준\"\n",
    "sample_embedding = get_embedding(sample_text)\n",
    "\n",
    "if sample_embedding:\n",
    "    print(f\"텍스트: {sample_text}\")\n",
    "    print(f\"임베딩 차원: {len(sample_embedding)}\")\n",
    "    print(f\"벡터 샘플 (처음 5개): {sample_embedding[:5]}\")\n",
    "else:\n",
    "    print(\"[아직 구현되지 않았습니다]\")\n",
    "\n",
    "# ============================================================\n",
    "# 실습 4: ChromaDB에 저장\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"[실습 4] Vector Database 구축 - ChromaDB\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ChromaDB 초기화 (이미 구현됨)\n",
    "print(\"\\n[진행중] ChromaDB 초기화...\")\n",
    "chroma_client = chromadb.Client(Settings(\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    anonymized_telemetry=False\n",
    "))\n",
    "\n",
    "try:\n",
    "    chroma_client.delete_collection(\"fire_law\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "fire_law_collection = chroma_client.create_collection(\n",
    "    name=\"fire_law\",\n",
    "    metadata={\"description\": \"소방기본법 10페이지\"}\n",
    ")\n",
    "print(\"[완료] 컬렉션 생성 완료\")\n",
    "\n",
    "# TODO: 청크 임베딩 및 저장\n",
    "print(\"\\n[실습] 청크를 Vector DB에 저장하기\")\n",
    "print(\"\"\"\n",
    "TODO: 각 청크를 임베딩하여 ChromaDB에 저장하세요\n",
    "\n",
    "힌트:\n",
    "1. for 반복문으로 law_chunks 순회\n",
    "2. 각 청크의 text를 get_embedding()으로 임베딩 생성\n",
    "3. fire_law_collection.add()로 저장\n",
    "   - ids: [chunk['id']]\n",
    "   - embeddings: [embedding]\n",
    "   - documents: [chunk['text']]\n",
    "   - metadatas: [{\"page\": chunk['page'], \"source\": \"소방기본법\"}]\n",
    "\n",
    "예시 코드:\n",
    "for i, chunk in enumerate(law_chunks):\n",
    "    embedding = get_embedding(chunk['text'])\n",
    "    fire_law_collection.add(\n",
    "        ids=[chunk['id']],\n",
    "        embeddings=[embedding],\n",
    "        documents=[chunk['text']],\n",
    "        metadatas=[{\"page\": chunk['page'], \"source\": \"소방기본법\"}]\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "if law_chunks and sample_embedding:\n",
    "    # TODO: 여기에 반복문 코드를 작성하세요\n",
    "    saved_count = 0  # 실제로 저장한 청크 수로 업데이트하세요\n",
    "    \n",
    "    if saved_count > 0:\n",
    "        print(f\"[완료] {saved_count}개 청크 저장 완료!\")\n",
    "    else:\n",
    "        print(\"[아직 구현되지 않았습니다]\")\n",
    "else:\n",
    "    print(\"[청킹과 임베딩을 먼저 구현해야 합니다]\")\n",
    "\n",
    "# ============================================================\n",
    "# 실습 5: RAG 검색 및 답변 생성\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"[실습 5] RAG 시스템 - 검색 후 답변 생성\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def search_fire_law(query: str, n_results: int = 3) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    소방기본법 검색 함수\n",
    "    \n",
    "    TODO: 질문을 임베딩하여 유사한 청크 검색하기\n",
    "    \n",
    "    힌트:\n",
    "    1. 질문을 get_embedding()으로 임베딩\n",
    "    2. fire_law_collection.query()로 검색\n",
    "       - query_embeddings: [query_embedding]\n",
    "       - n_results: n_results\n",
    "    3. 결과를 딕셔너리 리스트로 변환\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: 여기에 검색 코드 작성\n",
    "    # query_embedding = get_embedding(query)\n",
    "    # results = fire_law_collection.query(...)\n",
    "    # return [{\"text\": ..., \"page\": ..., \"source\": ...}, ...]\n",
    "    \n",
    "    return []\n",
    "\n",
    "def answer_with_rag(question: str) -> str:\n",
    "    \"\"\"\n",
    "    RAG 기반 답변 생성\n",
    "    \n",
    "    TODO: 검색 결과를 컨텍스트로 활용하여 답변 생성\n",
    "    \n",
    "    프로세스:\n",
    "    1. search_fire_law()로 관련 문서 검색\n",
    "    2. 검색 결과를 컨텍스트로 구성\n",
    "    3. LLM에게 컨텍스트와 질문 전달\n",
    "    4. LLM이 문서 기반 답변 생성\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: 검색 및 답변 생성 구현\n",
    "    # search_results = search_fire_law(question, n_results=3)\n",
    "    # context = \"\\n\\n\".join([f\"[출처: {r['source']}, {r['page']}페이지]\\n{r['text']}\" for r in search_results])\n",
    "    # response = client.chat.completions.create(...)\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "# ============================================================\n",
    "# 최종 테스트\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n[최종 테스트] RAG 시스템 실행\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_questions = [\n",
    "    \"소방시설 설치 대상은 어떻게 되나요?\",\n",
    "    \"소방시설 점검은 언제 해야 하나요?\",\n",
    "    \"위반 시 과태료는 얼마인가요?\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    print(f\"\\n[질문] {q}\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # 검색 결과 확인\n",
    "    results = search_fire_law(q, n_results=2)\n",
    "    if results:\n",
    "        print(\"[검색된 문서]\")\n",
    "        for i, r in enumerate(results, 1):\n",
    "            print(f\"  {i}. {r['source']} {r['page']}페이지\")\n",
    "            print(f\"     {r['text'][:150]}...\")\n",
    "        \n",
    "        # 답변 생성\n",
    "        print(\"\\n[답변]\")\n",
    "        answer = answer_with_rag(q)\n",
    "        print(answer if answer else \"[아직 구현되지 않았습니다]\")\n",
    "    else:\n",
    "        print(\"[검색 기능을 먼저 구현해야 합니다]\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# Lab 2 완료\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[완료] Lab 2 완료!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "학습 내용:\n",
    "1. PDF 텍스트 추출 (pdfplumber)\n",
    "2. 텍스트 청킹 (Chunking)\n",
    "3. 임베딩 생성 (Embedding)\n",
    "4. Vector DB 구축 (ChromaDB)\n",
    "5. RAG 검색 및 답변 생성\n",
    "\n",
    "핵심 함수:\n",
    "- search_fire_law(): 소방기본법 검색\n",
    "- answer_with_rag(): RAG 기반 답변\n",
    "\n",
    "다음 Lab:\n",
    "- Lab 3에서는 화재예방 가이드를 추가하여 다중 문서 검색 시스템을 구축합니다.\n",
    "\n",
    "실습 체크리스트:\n",
    "[ ] 실습 1: extract_text_from_pdf 함수 완성\n",
    "[ ] 실습 2: chunk_text 함수 완성\n",
    "[ ] 실습 3: get_embedding 함수 완성\n",
    "[ ] 실습 4: ChromaDB 저장 루프 완성\n",
    "[ ] 실습 5: search_fire_law와 answer_with_rag 함수 완성\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
