{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb05a70-3799-47f3-90e5-956096d0960f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fb05a70-3799-47f3-90e5-956096d0960f",
        "outputId": "517576ca-5084-4b5f-f079-0b6d27c0d0c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.7/20.7 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m[API 키 입력] OpenAI API 키를 입력하세요\n",
            "[완료] 환경 설정 완료!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Lab 5: Gradio UI + 최종 통합 (40분)\n",
        "# 소방청 민원처리 AI Agent 교육\n",
        "\n",
        "\"\"\"\n",
        "학습 목표:\n",
        "- Gradio를 활용한 웹 UI 구축\n",
        "- Lab 1-4의 모든 기능을 UI에 통합\n",
        "- 실전 민원 처리 시스템 완성\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================\n",
        "# 환경 설정\n",
        "# ============================================================\n",
        "import sys,os\n",
        "if 'google.colab' in sys.modules:\n",
        "    !pip install openai chromadb pdfplumber gradio -q\n",
        "\n",
        "import getpass\n",
        "from openai import OpenAI\n",
        "import pdfplumber\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "import gradio as gr\n",
        "from typing import List, Dict\n",
        "from datetime import datetime\n",
        "\n",
        "# API 키 설정\n",
        "print(\"[API 키 입력] OpenAI API 키를 입력하세요\")\n",
        "api_key = \"\".strip()\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "print(\"[완료] 환경 설정 완료!\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "rhOMlkP6w7Bn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhOMlkP6w7Bn",
        "outputId": "3151b45e-8a57-45db-fe6a-c7c21bb6b88a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[진행중] 시스템 초기화 중...\n",
            "[진행중] Vector DB 구축 중... (1-2분 소요)\n",
            "[완료] 시스템 준비 완료!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Lab 1-4 함수 통합 (빠른 재구축)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n[진행중] 시스템 초기화 중...\")\n",
        "\n",
        "# 기본 함수들\n",
        "def classify_complaint(text: str) -> Dict[str, str]:\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"소방 민원을 분류하고 다음 형식으로 답변하세요:\n",
        "\n",
        "카테고리: [화재신고/소방시설/법규위반/일반문의]\n",
        "긴급도: [높음/보통/낮음]\n",
        "키워드: [핵심 키워드 3개]\n",
        "요약: [한 줄 요약]\"\"\"\n",
        "            },\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=200\n",
        "    )\n",
        "    return {\"원문\": text, \"분류_결과\": response.choices[0].message.content}\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: str, max_pages: int = None) -> List[Dict]:\n",
        "    pages_data = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        total_pages = len(pdf.pages) if max_pages is None else min(max_pages, len(pdf.pages))\n",
        "        for i in range(total_pages):\n",
        "            text = pdf.pages[i].extract_text()\n",
        "            pages_data.append({\"page_num\": i + 1, \"text\": text, \"char_count\": len(text)})\n",
        "    return pages_data\n",
        "\n",
        "def chunk_text(pages_data: List[Dict], chunk_size: int = 500, overlap: int = 50) -> List[Dict]:\n",
        "    chunks = []\n",
        "    chunk_id = 0\n",
        "    for page_data in pages_data:\n",
        "        text = page_data['text']\n",
        "        page_num = page_data['page_num']\n",
        "        start = 0\n",
        "        while start < len(text):\n",
        "            end = start + chunk_size\n",
        "            chunk_text = text[start:end]\n",
        "            if chunk_text.strip():\n",
        "                chunks.append({\n",
        "                    \"id\": f\"chunk_{chunk_id}\",\n",
        "                    \"text\": chunk_text,\n",
        "                    \"page\": page_num,\n",
        "                    \"start_pos\": start\n",
        "                })\n",
        "                chunk_id += 1\n",
        "            start = end - overlap\n",
        "    return chunks\n",
        "\n",
        "def get_embedding(text: str) -> List[float]:\n",
        "    response = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=text\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# Vector DB 구축\n",
        "print(\"[진행중] Vector DB 구축 중... (1-2분 소요)\")\n",
        "chroma_client = chromadb.Client(Settings(\n",
        "    persist_directory=\"./chroma_db\",\n",
        "    anonymized_telemetry=False\n",
        "))\n",
        "\n",
        "try:\n",
        "    chroma_client.delete_collection(\"fire_law\")\n",
        "    chroma_client.delete_collection(\"fire_prevention\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 소방기본법\n",
        "fire_law_pages = extract_text_from_pdf(\"소방기본법.pdf\", max_pages=10)\n",
        "fire_law_chunks = chunk_text(fire_law_pages)\n",
        "fire_law_collection = chroma_client.create_collection(\"fire_law\")\n",
        "for chunk in fire_law_chunks:\n",
        "    embedding = get_embedding(chunk['text'])\n",
        "    fire_law_collection.add(\n",
        "        ids=[f\"law_{chunk['id']}\"],\n",
        "        embeddings=[embedding],\n",
        "        documents=[chunk['text']],\n",
        "        metadatas=[{\"page\": chunk['page'], \"source\": \"소방기본법\"}]\n",
        "    )\n",
        "\n",
        "# 화재예방\n",
        "prevention_pages = extract_text_from_pdf(\"화재예방.pdf\")\n",
        "prevention_chunks = chunk_text(prevention_pages)\n",
        "prevention_collection = chroma_client.create_collection(\"fire_prevention\")\n",
        "for chunk in prevention_chunks:\n",
        "    embedding = get_embedding(chunk['text'])\n",
        "    prevention_collection.add(\n",
        "        ids=[f\"prev_{chunk['id']}\"],\n",
        "        embeddings=[embedding],\n",
        "        documents=[chunk['text']],\n",
        "        metadatas=[{\"page\": chunk['page'], \"source\": \"화재예방가이드\"}]\n",
        "    )\n",
        "\n",
        "# 검색 함수\n",
        "def search_fire_law(query: str, n_results: int = 3) -> List[Dict]:\n",
        "    query_embedding = get_embedding(query)\n",
        "    results = fire_law_collection.query(query_embeddings=[query_embedding], n_results=n_results)\n",
        "    return [\n",
        "        {\"text\": results['documents'][0][i], \"page\": results['metadatas'][0][i]['page'], \"source\": results['metadatas'][0][i]['source']}\n",
        "        for i in range(len(results['documents'][0]))\n",
        "    ]\n",
        "\n",
        "def search_fire_prevention(query: str, n_results: int = 3) -> List[Dict]:\n",
        "    query_embedding = get_embedding(query)\n",
        "    results = prevention_collection.query(query_embeddings=[query_embedding], n_results=n_results)\n",
        "    return [\n",
        "        {\"text\": results['documents'][0][i], \"page\": results['metadatas'][0][i]['page'], \"source\": results['metadatas'][0][i]['source']}\n",
        "        for i in range(len(results['documents'][0]))\n",
        "    ]\n",
        "\n",
        "def search_both_sources(query: str, n_results_per_source: int = 2) -> Dict:\n",
        "    return {\n",
        "        \"법령\": search_fire_law(query, n_results_per_source),\n",
        "        \"예방가이드\": search_fire_prevention(query, n_results_per_source),\n",
        "        \"total_count\": n_results_per_source * 2\n",
        "    }\n",
        "\n",
        "# 보고서 생성\n",
        "def generate_complaint_report(complaint_text: str) -> Dict:\n",
        "    classification = classify_complaint(complaint_text)\n",
        "    search_results = search_both_sources(complaint_text, n_results_per_source=2)\n",
        "\n",
        "    law_context = \"\\n\".join([f\"- {r['source']} {r['page']}p: {r['text'][:200]}\" for r in search_results['법령']])\n",
        "    prevention_context = \"\\n\".join([f\"- {r['source']} {r['page']}p: {r['text'][:200]}\" for r in search_results['예방가이드']])\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"\"\"당신은 소방청 민원 처리 담당자입니다.\n",
        "다음 형식으로 공식 보고서를 작성하세요:\n",
        "\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "【민원 처리 보고서】\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "\n",
        "1. 민원 내용\n",
        "   [민원 요약]\n",
        "\n",
        "2. 분류 결과\n",
        "   [카테고리, 긴급도, 키워드]\n",
        "\n",
        "3. 관련 법령 및 근거\n",
        "   [소방기본법 관련 내용]\n",
        "\n",
        "4. 처리 방안\n",
        "   [구체적인 대응 방법]\n",
        "\n",
        "5. 예방 가이드\n",
        "   [화재예방 참고사항]\n",
        "\n",
        "6. 담당 부서 및 처리 기한\n",
        "   [추천 담당 부서 및 기한]\n",
        "\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
        "작성일시: [현재 날짜]\n",
        "작성자: 소방청 담당자\n",
        "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\"\"\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"다음 민원에 대한 처리 보고서를 작성하세요.\n",
        "\n",
        "[민원 내용]\n",
        "{complaint_text}\n",
        "\n",
        "[분류 정보]\n",
        "{classification['분류_결과']}\n",
        "\n",
        "[참고 - 소방기본법]\n",
        "{law_context}\n",
        "\n",
        "[참고 - 화재예방 가이드]\n",
        "{prevention_context}\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.4,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    report = response.choices[0].message.content\n",
        "\n",
        "    return {\n",
        "        \"민원원문\": complaint_text,\n",
        "        \"분류\": classification,\n",
        "        \"법령검색\": search_results['법령'],\n",
        "        \"예방검색\": search_results['예방가이드'],\n",
        "        \"보고서\": report\n",
        "    }\n",
        "\n",
        "print(\"[완료] 시스템 준비 완료!\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "VJl-EJXxxAZe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJl-EJXxxAZe",
        "outputId": "798d75a4-0a67-445c-efea-51221b4a6235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "[실습 1] Gradio UI 함수 구현\n",
            "============================================================\n",
            "\n",
            "[완료] UI 함수 구현 완료\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 실습 1: Gradio UI 함수\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"[실습 1] Gradio UI 함수 구현\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def process_complaint_ui(complaint_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Gradio UI용 래퍼 함수\n",
        "\n",
        "    입력: 민원 내용 (텍스트)\n",
        "    출력: 처리 보고서 (텍스트)\n",
        "    \"\"\"\n",
        "    # 입력 검증\n",
        "    if not complaint_text or not complaint_text.strip():\n",
        "        return \"[경고] 민원 내용을 입력해주세요.\"\n",
        "\n",
        "    if len(complaint_text) < 10:\n",
        "        return \"[경고] 민원 내용이 너무 짧습니다. 최소 10자 이상 입력해주세요.\"\n",
        "\n",
        "    try:\n",
        "        # 보고서 생성\n",
        "        result = generate_complaint_report(complaint_text)\n",
        "        return result['보고서']\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"\"\"[오류 발생]\n",
        "\n",
        "오류 내용: {str(e)}\n",
        "\n",
        "해결 방법:\n",
        "1. API 키가 유효한지 확인하세요\n",
        "2. PDF 파일이 올바르게 업로드되었는지 확인하세요\n",
        "3. 인터넷 연결을 확인하세요\n",
        "4. 민원 내용을 다시 입력해보세요\"\"\"\n",
        "\n",
        "print(\"\\n[완료] UI 함수 구현 완료\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "Y70Q4Z3bxYLn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y70Q4Z3bxYLn",
        "outputId": "3763a9bc-b0a2-4432-b3cd-d77e037883eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[실습 2] Gradio 인터페이스 구축\n",
            "============================================================\n",
            "\n",
            "[완료] Gradio 인터페이스 구축 완료\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 실습 2: Gradio 인터페이스 구축\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"[실습 2] Gradio 인터페이스 구축\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 예시 민원들\n",
        "examples = [\n",
        "    [\"아파트 복도에 소화기가 없는데 괜찮은가요?\"],\n",
        "    [\"식당을 운영하는데 소방시설 점검은 언제 받아야 하나요?\"],\n",
        "    [\"소방차 전용구역에 주차했다가 과태료를 받았습니다.\"],\n",
        "    [\"회사 사무실 소방시설 정기 점검 주기가 궁금합니다.\"],\n",
        "    [\"주택에 화재경보기 설치가 의무인가요?\"]\n",
        "]\n",
        "\n",
        "# Gradio 인터페이스 생성\n",
        "interface = gr.Interface(\n",
        "    fn=process_complaint_ui,\n",
        "    inputs=gr.Textbox(\n",
        "        label=\"민원 내용\",\n",
        "        placeholder=\"처리할 민원 내용을 입력하세요...\\n\\n예시:\\n- 아파트 복도에 소화기가 없습니다\\n- 식당 소방시설 점검 주기가 궁금합니다\\n- 소방차 전용구역 주차 과태료 문의\",\n",
        "        lines=7,\n",
        "        max_lines=10\n",
        "    ),\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"처리 보고서\",\n",
        "        lines=25,\n",
        "        max_lines=30\n",
        "    ),\n",
        "    title=\"소방청 민원처리 AI Agent\",\n",
        "    description=\"\"\"\n",
        "    ### 민원 내용을 입력하면 자동으로 처리 보고서를 생성합니다\n",
        "\n",
        "    **자동 수행 기능:**\n",
        "    1. 민원 자동 분류 (카테고리, 긴급도, 키워드)\n",
        "    2. 관련 법령 검색 (소방기본법)\n",
        "    3. 예방 가이드 검색 (화재예방)\n",
        "    4. 공식 처리 보고서 생성\n",
        "\n",
        "    **사용 방법:**\n",
        "    - 아래 예시를 클릭하거나 직접 민원을 입력하세요\n",
        "    - 생성 버튼을 누르면 약 10-20초 후 보고서가 생성됩니다\n",
        "    \"\"\",\n",
        "    examples=examples,\n",
        "    theme=gr.themes.Soft(),\n",
        "    article=\"\"\"\n",
        "    ---\n",
        "    ### 시스템 정보\n",
        "    - **모델:** GPT-4o-mini\n",
        "    - **임베딩:** text-embedding-3-small\n",
        "    - **Vector DB:** ChromaDB\n",
        "    - **데이터:** 소방기본법 (10p) + 화재예방 가이드 (44p)\n",
        "\n",
        "    ### 주의사항\n",
        "    - 생성된 보고서는 참고용이며, 최종 결정은 담당자 검토 후 확정됩니다\n",
        "    - 법령은 최신 개정본을 별도로 확인하세요\n",
        "    - 긴급 상황은 119로 즉시 신고하세요\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(\"\\n[완료] Gradio 인터페이스 구축 완료\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "jfSCRJ5_xabH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfSCRJ5_xabH",
        "outputId": "47bc58ca-45a3-4abd-96b7-0f69d2b71a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "============================================================\n",
            "[실습 3] Gradio UI 실행\n",
            "============================================================\n",
            "\n",
            "[안내] Gradio UI를 실행합니다.\n",
            "\n",
            "실행 후:\n",
            "1. 자동으로 public URL이 생성됩니다\n",
            "2. URL을 클릭하여 웹 인터페이스를 엽니다\n",
            "3. 민원을 입력하고 테스트합니다\n",
            "\n",
            "Colab 환경에서는:\n",
            "- share=True로 설정하여 외부 접속 가능한 링크 생성\n",
            "- 링크는 72시간 동안 유효\n",
            "- 다른 사람들과 공유 가능\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 실습 3: UI 실행 및 테스트\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"[실습 3] Gradio UI 실행\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "[안내] Gradio UI를 실행합니다.\n",
        "\n",
        "실행 후:\n",
        "1. 자동으로 public URL이 생성됩니다\n",
        "2. URL을 클릭하여 웹 인터페이스를 엽니다\n",
        "3. 민원을 입력하고 테스트합니다\n",
        "\n",
        "Colab 환경에서는:\n",
        "- share=True로 설정하여 외부 접속 가능한 링크 생성\n",
        "- 링크는 72시간 동안 유효\n",
        "- 다른 사람들과 공유 가능\n",
        "\"\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "GbbIsyEjxdjV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GbbIsyEjxdjV",
        "outputId": "a0ede103-3ee0-43ef-a99f-f783e172f4a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[완료] Lab 5 완료!\n",
            "============================================================\n",
            "\n",
            "학습 내용:\n",
            "1. Gradio 기본 사용법\n",
            "2. UI 함수 구현 (입력 검증, 오류 처리)\n",
            "3. 인터페이스 구성 (입력/출력/예시)\n",
            "4. 웹 UI 배포 (share=True)\n",
            "\n",
            "최종 시스템:\n",
            "- 민원 입력 → 자동 분류 → 법령 검색 → 보고서 생성\n",
            "- 웹 인터페이스로 누구나 쉽게 사용 가능\n",
            "- 외부 공유 가능한 링크 생성\n",
            "\n",
            "실전 활용:\n",
            "1. 부서 내 공유하여 실무에 활용\n",
            "2. 다양한 민원으로 테스트하여 정확도 검증\n",
            "3. 필요시 프롬프트 수정하여 맞춤화\n",
            "\n",
            "전체 Lab 완료!\n",
            "Lab 1: API 기초\n",
            "Lab 2: RAG 기초\n",
            "Lab 3: 고급 검색\n",
            "Lab 4: 보고서 생성\n",
            "Lab 5: Gradio UI ← 현재\n",
            "\n",
            "이제 실전 민원을 처리해보세요!\n",
            "\n",
            "\n",
            "[실행] Gradio UI 시작...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://d7dde2f65acabf3c27.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://d7dde2f65acabf3c27.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d7dde2f65acabf3c27.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 최종 실행\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"[완료] Lab 5 완료!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\"\"\n",
        "학습 내용:\n",
        "1. Gradio 기본 사용법\n",
        "2. UI 함수 구현 (입력 검증, 오류 처리)\n",
        "3. 인터페이스 구성 (입력/출력/예시)\n",
        "4. 웹 UI 배포 (share=True)\n",
        "\n",
        "최종 시스템:\n",
        "- 민원 입력 → 자동 분류 → 법령 검색 → 보고서 생성\n",
        "- 웹 인터페이스로 누구나 쉽게 사용 가능\n",
        "- 외부 공유 가능한 링크 생성\n",
        "\n",
        "실전 활용:\n",
        "1. 부서 내 공유하여 실무에 활용\n",
        "2. 다양한 민원으로 테스트하여 정확도 검증\n",
        "3. 필요시 프롬프트 수정하여 맞춤화\n",
        "\n",
        "전체 Lab 완료!\n",
        "Lab 1: API 기초\n",
        "Lab 2: RAG 기초\n",
        "Lab 3: 고급 검색\n",
        "Lab 4: 보고서 생성\n",
        "Lab 5: Gradio UI ← 현재\n",
        "\n",
        "이제 실전 민원을 처리해보세요!\n",
        "\"\"\")\n",
        "\n",
        "# Gradio 실행\n",
        "print(\"\\n[실행] Gradio UI 시작...\")\n",
        "interface.launch(share=True, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
